{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1aeaa6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "import pyttsx3 \n",
    "import json\n",
    "import numpy as np \n",
    "from tensorflow import keras\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import neighbors\n",
    "import colorama\n",
    "colorama.init\n",
    "from colorama import Fore, Style, Back\n",
    "import random\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3d936cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('intents.json') as file:\n",
    "    data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a432d20e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3441: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version.\n",
      "\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "b'Skipping line 3350: expected 12 fields, saw 13\\nSkipping line 4704: expected 12 fields, saw 13\\nSkipping line 5879: expected 12 fields, saw 13\\nSkipping line 8981: expected 12 fields, saw 13\\n'\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('books.csv', error_bad_lines = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "caff08b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting average rating column into categorical column\n",
    "def num_into_obj(x):\n",
    "    if x>=0 and x<=1:\n",
    "        return 'between 0 and 1'\n",
    "    elif x>1 and x<=2:\n",
    "        return 'between 1 and 2'\n",
    "    elif x>2 and x<=3:\n",
    "        return 'between 2 and 3'\n",
    "    elif x>3 and x<=4:\n",
    "        return 'between 3 and 4'\n",
    "    else:\n",
    "        return 'between 4 and 5'\n",
    "    \n",
    "df['rating_obj'] = df['average_rating'].apply(num_into_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81728a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's encode the categorical column\n",
    "rating_df = pd.get_dummies(df['rating_obj'])\n",
    "#rating_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd24dbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's encode the language code column as well\n",
    "language_df = pd.get_dummies(df['language_code'])\n",
    "#language_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f67d561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's concat both the data frames and set the title column as the index \n",
    "features = pd.concat([rating_df, language_df, df['average_rating'], df['ratings_count'],df['title']], axis=1)\n",
    "features.set_index('title', inplace=True)\n",
    "#features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1b73c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_scaler = MinMaxScaler()\n",
    "features_scaled = min_max_scaler.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53cef58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = neighbors.NearestNeighbors(n_neighbors=6, algorithm='ball_tree', metric='euclidean')\n",
    "model.fit(features_scaled)\n",
    "dist, idlist = model.kneighbors(features_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d372eadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the recognizer \n",
    "r = sr.Recognizer() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "098dd517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert text to\n",
    "# speech\n",
    "def SpeakText(command):\n",
    "      \n",
    "    # Initialize the engine\n",
    "    engine = pyttsx3.init()\n",
    "    engine.say(command) \n",
    "    engine.runAndWait()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2168a91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop infinitely for user to\n",
    "# speak\n",
    "model = keras.models.load_model('voice_assistant')\n",
    "with open('tokenizer.pickle','rb') as handle:\n",
    "    tokenizer = pickle.load(handle)\n",
    "with open('lbl_encoder.pickle','rb') as ecn:\n",
    "    lbl_encoder = pickle.load(ecn)\n",
    "max_len = 20  \n",
    "while(1):    \n",
    "      \n",
    "    # Exception handling to handle\n",
    "    # exceptions at the runtime\n",
    "    try:\n",
    "          \n",
    "        # use the microphone as source for input.\n",
    "        with sr.Microphone() as source2:\n",
    "              \n",
    "            # wait for a second to let the recognizer\n",
    "            # adjust the energy threshold based on\n",
    "            # the surrounding noise level \n",
    "            r.adjust_for_ambient_noise(source2, duration=0.2)\n",
    "              \n",
    "            #listens for the user's input \n",
    "            audio2 = r.listen(source2)\n",
    "              \n",
    "            # Using ggogle to recognize audio\n",
    "            MyText = r.recognize_google(audio2)\n",
    "            MyText = MyText.lower()\n",
    "  \n",
    "\n",
    "        \n",
    "            #print(Fore.LIGHTBLUE_EX + \"User: \"+ Style.RESET_ALL,end=\"\")\n",
    "            #inp = input()\n",
    "            if MyText.lower() == \"bye\":\n",
    "                break\n",
    "            if MyText.lower() == \"book search\":\n",
    "                print(\"Tell book name you like\")\n",
    "                SpeakText(\"Tell book name you like\")\n",
    "                while(1):\n",
    "                    try:\n",
    "                        with sr.Microphone() as source2:\n",
    "                            r.adjust_for_ambient_noise(source2, duration=0.2)\n",
    "                            audio2 = r.listen(source2)\n",
    "                            MyBook = r.recognize_google(audio2)\n",
    "                            MyBooks = MyBook.lower()\n",
    "                            book=MyBooks.title()\n",
    "                            print(book)\n",
    "                                 \n",
    "                            def BookRecommender(book):\n",
    "                                book_list_name = []\n",
    "                                book_id = df[df['title'] == book].index\n",
    "                                book_id = book_id[0]\n",
    "                                for newid in idlist[book_id]:\n",
    "                                    book_list_name.append(df.loc[newid].title)\n",
    "                                    SpeakText(df.loc[newid].title)\n",
    "                                    print(df.loc[newid].title)\n",
    "                                return\n",
    "                            if MyText.lower() == \"thank you\":\n",
    "                                break\n",
    "                            #print(Fore.GREEN + \"NUBI: \"+\"I would prefer that you read.\")\n",
    "                            #SpeakText(\"I would prefer that you read\")\n",
    "                            BookRecommender(book)    \n",
    "                            \n",
    "                    except sr.RequestError as e:\n",
    "                        print(\"Could not request results; {0}\".format(e))\n",
    "                        \n",
    "            result = model.predict(keras.preprocessing.sequence.pad_sequences(tokenizer.texts_to_sequences([MyText]),\n",
    "                                                                           truncating='post',maxlen=max_len))\n",
    "        \n",
    "            tag = lbl_encoder.inverse_transform([np.argmax(result)])\n",
    "            for i in data['intents']:\n",
    "                if i['tag']==tag:\n",
    "                    print(Fore.GREEN + \"NUBI: \"+ Style.RESET_ALL,np.random.choice(i['responses']))\n",
    "                    #print(\"Did you say \"+np.random.choice(i['responses']))\n",
    "                    SpeakText(np.random.choice(i['responses']))     \n",
    "            \n",
    "    except sr.RequestError as e:\n",
    "        print(\"Could not request results; {0}\".format(e))\n",
    "          \n",
    "    except sr.UnknownValueError:\n",
    "        print( \"NUBI:I can't hear you\")\n",
    "        SpeakText(\"I can't hear you\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124dbf06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
